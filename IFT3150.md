---
layout: page
title: IFT3150
---

### Superviseur
[Fabian Bastin](http://www.iro.umontreal.ca/~bastin/)

bastin (AT) iro.umontreal.ca

Bureau 3367, Pavillon André-Aisenstadt

### Résumé
Le succès actuel des méthodes de réseaux neuronaux, en particulier de réseaux profonds, ont eu comme effet secondaire de populariser l’algorithme du gradient stochastique, connu également en programmation stochastique comme la méthode d’approximation stochastique parmi la communauté de programmation non-linéaire. Bien qu’à ce jour, de nombreuses questions demeurent ouvertes, des progrès significatifs ont été obtenus dans l’étude de la convergence de la méthode ainsi que dans la recherche de stratégies d’accélération de la méthode.

Cette méthode d’optimisation demeure toutefois marginale dans le cadre de l’estimation de modèles de choix discrets, or le problème d’estimation par maximum de vraisemblance d’un modèle logit multinomial est mathématiquement très similaire au problème d’entraînement d’un réseau neuronal présentant des fonctions d’activation sigmoïdes. Pourtant, certaines extensions du modèle logit, en particulier le modèle mixed logit, demeure à ce jour numériquement coûteux à estimer comme chaque observation requiert d’approximer l’espérance de la probabilité de choix, typiquement par intégration Monte Carlo.

Le but de ce projet est d’adapter l’algorithme du gradient stochastique pour l’estimation de modèles mixed logit par maximum de vraisemblance, et de vérifier numériquement son efficacité tant en termes de qualité d’estimation que de vitesse de convergence. Dans un premier temps, la taille d’approximation sera fixée pour chaque individu, permettant de comparer la méthode avec une approche directe, ou méthode batch. Par après, diverses extensions seront envisagées pour prendre en compte les faiblesses de l’algorithme de gradient stochastique que du modèle mixed logit. Tout d’abord, il est connu que le choix de la longueur de pas à chaque itération, aussi appelé taux d’apprentissage dans la communauté d’intelligence artificielle, influence significativement le succès ainsi que la rapidité de la méthode de gradient stochastique. En tenant compte des résultats théoriques récents, nous essayerons d’améliorer et d’automatiser la longueur de pas. Dans un second temps, nous intégrerons une approximation de second ordre, basée sur l’identité de l’information de Fisher, pour accélérer la méthode. Enfin, une des difficultés majeures des modèles mixed logit est la qualité d’approximation de l’espérance de chaque observation, qui non seulement affecte la précision des résultats d’estimation, mais est également à l’origine d’un biais dans le cadre de l’estimation par maximum de vraisemblance, en raison de l’opérateur logarithmique. Nous tâcherons de définir une approche de gradient stochastique à deux niveaux, variant à chaque itération non seulement l’ensemble d’observations considérées (souvent réduite à un singleton), mais également l’échantillonnage Monte Carlo utilisé pour approximer l’espérance de probabilité de choix.

### Abstract
The current success of neural network methods, particularly deep networks, has had as a side effect to popularize the stochastic gradient algorithm, also known in stochastic programming as the stochastic approximation method among the non-linear programming community. Although many questions remain open today, significant progress has been made in the study of the method's convergence and in the search for strategies to accelerate the method.

This optimization method remains marginal in the estimation of discrete choice models but the problem of maximum likelihood estimation of a multinomial logit model is mathematically very similar to the problem of training a network neuronal cells exhibiting sigmoid activation functions. However, some extensions of the logit model, in particular the mixed logit model, remain numerically costly to estimate as each observation requires approximating the expectation of the probability of choice, typically by Monte Carlo integration.

The aim of this project is to adapt the algorithm of the stochastic gradient for the estimation of mixed logit models by maximum likelihood and to verify numerically its efficiency in terms of estimation quality as well as of convergence speed. First, the approximation size will be fixed for each individual, allowing to compare the method with a direct approach, or batch method. Thereafter, various extensions will be considered to take into account the weaknesses of the stochastic gradient algorithm as of the mixed logit model. Firstly, it is known that the choice of step length at each iteration, also called learning rate in the artificial intelligence community, significantly influences the success as well as the rapidity of the stochastic gradient method. Taking into account the recent theoretical results, we will try to improve and automate the step length. Secondly, we will integrate a second-order approximation, based on the Fisher information identity, to accelerate the method. Finally, one of the major difficulties of the mixed logit models is the quality of the approximation of the expectation of each observation, which not only affects the accuracy of the estimation results but is also the cause of a bias in the framework of the maximum likelihood estimate, due to the logarithmic operator. We will try to define a two-level stochastic gradient approach, varying at each iteration not only the set of observations considered (often reduced to a singleton) but also the Monte Carlo sampling used to approximate the probability expectation of choice.
