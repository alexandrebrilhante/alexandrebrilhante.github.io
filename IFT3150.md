---
layout: page
title: IFT3150
---

### Description
Le succès actuel des méthodes de réseaux neuronaux, en particulier de réseaux profonds, ont eu comme effet secondaire de populariser l’algorithme du gradient stochastique, connu également en programmation stochastique comme la méthode d’approximation stochastique parmi la communauté de programmation non-linéaire. Bien qu’à ce jour, de nombreuses questions demeurent ouvertes, des progrès significatifs ont été obtenus dans l’étude de la convergence de la méthode ainsi que dans la recherche de stratégies d’accélération de la méthode.

Cette méthode d’optimisation demeure toutefois marginale dans le cadre de l’estimation de modèles de choix discrets, or le problème d’estimation par maximum de vraisemblance d’un modèle logit multinomial est mathématiquement très similaire au problème d’entraînement d’un réseau neuronal présentant des fonctions d’activation sigmoïdes. Pourtant, certaines extensions du modèle logit, en particulier le modèle mixed logit, demeure à ce jour numériquement coûteux à estimer comme chaque observation requiert d’approximer l’espérance de la probabilité de choix, typiquement par intégration Monte Carlo.

Le but de ce projet est d’adapter l’algorithme du gradient stochastique pour l’estimation de modèles mixed logit par maximum de vraisemblance, et de vérifier numériquement son efficacité tant en termes de qualité d’estimation que de vitesse de convergence. Dans un premier temps, la taille d’approximation sera fixée pour chaque individu, permettant de comparer la méthode avec une approche directe, ou méthode batch. Par après, diverses extensions seront envisagées pour prendre en compte les faiblesses de l’algorithme de gradient stochastique que du modèle mixed logit. Tout d’abord, il est connu que le choix de la longueur de pas à chaque itération, aussi appelé taux d’apprentissage dans la communauté d’intelligence artificielle, influence significativement le succès ainsi que la rapidité de la méthode de gradient stochastique. En tenant compte des résultats théoriques récents, nous essayerons d’améliorer et d’automatiser la longueur de pas. Dans un second temps, nous intégrerons une approximation de second ordre, basée sur l’identité de l’information de Fisher, pour accélérer la méthode. Enfin, une des difficultés majeures des modèles mixed logit est la qualité d’approximation de l’espérance de chaque observation, qui non seulement affecte la précision des résultats d’estimation, mais est également à l’origine d’un biais dans le cadre de l’estimation par maximum de vraisemblance, en raison de l’opérateur logarithmique. Nous tâcherons de définir une approche de gradient stochastique à deux niveaux, variant à chaque itération non seulement l’ensemble d’observations considérées (souvent réduite à un singleton), mais également l’échantillonnage Monte-Carlo utilisé pour approximer l’espérance de probabilité de choix.

### Superviseur
[Fabian Bastin](http://www.iro.umontreal.ca/~bastin/)
